from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, Response
import pandas as pd
import numpy as np
import asyncio
import io
import os
import sys
from typing import Dict, List, Any
import logging
import json
from datetime import datetime

# Add current directory to Python path for imports
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

# Debug import process
print("üîç Debug: Starting import process...")
print(f"üìÅ Current working directory: {os.getcwd()}")
print(f"üìÇ Files in current directory: {os.listdir('.')}")
print(f"üìÅ Script directory: {current_dir}")
print(f"üêç Python path: {sys.path}")

# Import NLP processor with multiple fallback methods
NLP_PROCESSOR_CLASS = None
GEMINI_SERVICE_CLASS = None

try:
    print("üîÑ Attempting to import NLPProcessor...")
    
    # Method 1: Direct import (same directory)
    try:
        from nlp_processor import NLPProcessor
        NLP_PROCESSOR_CLASS = NLPProcessor
        print("‚úÖ Successfully imported from nlp_processor (same directory)")
        
    except ImportError as e1:
        print(f"‚ö†Ô∏è Method 1 failed: {e1}")
        
        # Method 2: Relative import from app
        try:
            from .nlp_processor import NLPProcessor
            NLP_PROCESSOR_CLASS = NLPProcessor
            print("‚úÖ Successfully imported from .nlp_processor (relative)")
            
        except ImportError as e2:
            print(f"‚ö†Ô∏è Method 2 failed: {e2}")
            
            # Method 3: Absolute import
            try:
                from app.nlp_processor import NLPProcessor
                NLP_PROCESSOR_CLASS = NLPProcessor
                print("‚úÖ Successfully imported from app.nlp_processor (absolute)")
                
            except ImportError as e3:
                print(f"‚ö†Ô∏è Method 3 failed: {e3}")
                raise e3
    
    if NLP_PROCESSOR_CLASS:
        print(f"‚úÖ NLPProcessor class ready: {NLP_PROCESSOR_CLASS}")
    
except Exception as e:
    print(f"‚ùå NLP Import failed: {type(e).__name__}: {e}")
    import traceback
    traceback.print_exc()
    NLP_PROCESSOR_CLASS = None

# Import Gemini AI Service
try:
    print("üîÑ Attempting to import Gemini AI Service...")
    
    try:
        from gemini_integration import GeminiAIService, enhance_insights_with_ai, setup_gemini_config
        GEMINI_SERVICE_CLASS = GeminiAIService
        print("‚úÖ Successfully imported Gemini AI Service")
    except ImportError as e1:
        try:
            from .gemini_integration import GeminiAIService, enhance_insights_with_ai, setup_gemini_config
            GEMINI_SERVICE_CLASS = GeminiAIService
            print("‚úÖ Successfully imported Gemini AI Service (relative)")
        except ImportError as e2:
            try:
                from app.gemini_integration import GeminiAIService, enhance_insights_with_ai, setup_gemini_config
                GEMINI_SERVICE_CLASS = GeminiAIService
                print("‚úÖ Successfully imported Gemini AI Service (absolute)")
            except ImportError as e3:
                print(f"‚ö†Ô∏è Gemini import failed: {e3}")
                GEMINI_SERVICE_CLASS = None
                # Create fallback functions
                async def enhance_insights_with_ai(*args, **kwargs):
                    return {"error": "Gemini AI not available"}
                def setup_gemini_config():
                    return {"api_key_configured": False, "fallback_available": True}

except Exception as e:
    print(f"‚ùå Gemini import failed: {e}")
    GEMINI_SERVICE_CLASS = None

print(f"üéØ Final result: NLP_PROCESSOR_CLASS = {NLP_PROCESSOR_CLASS}")
print(f"ü§ñ Final result: GEMINI_SERVICE_CLASS = {GEMINI_SERVICE_CLASS}")

app = FastAPI(
    title="Post-Test Survey Analysis Dashboard",
    description="AI/NLP Dashboard for Post-Test Survey Analysis with Enhanced Thai Language Processing + Gemini AI + SSense API",
    version="3.0.0"
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Initialize processors
nlp_processor = None
gemini_ai_key = os.getenv('GEMINI_API_KEY')

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@app.on_event("startup")
async def startup_event():
    """Initialize NLP processor and AI services on startup"""
    global nlp_processor, gemini_ai_key
    
    print(f"üöÄ Startup event - NLP_PROCESSOR_CLASS: {NLP_PROCESSOR_CLASS}")
    print(f"ü§ñ Startup event - GEMINI_SERVICE_CLASS: {GEMINI_SERVICE_CLASS}")
    
    # Initialize NLP Processor
    if NLP_PROCESSOR_CLASS:
        try:
            print("üîß Creating NLP processor instance...")
            nlp_processor = NLP_PROCESSOR_CLASS(analysis_method=2)  # Change method
            print("üîß Initializing NLP processor...")
            await nlp_processor.initialize()
            print("‚úÖ Enhanced NLP Processor initialized successfully")
            logger.info("‚úÖ Enhanced NLP Processor initialized successfully")
        except Exception as e:
            print(f"‚ùå Failed to initialize NLP processor: {e}")
            logger.error(f"‚ùå Failed to initialize NLP processor: {e}")
            import traceback
            traceback.print_exc()
            nlp_processor = None
    else:
        print("‚ö†Ô∏è NLP Processor not available - will return error for analysis requests")
        logger.warning("‚ö†Ô∏è NLP Processor not available")
    
    # Check Gemini AI configuration
    if GEMINI_SERVICE_CLASS:
        gemini_config = setup_gemini_config()
        if gemini_config["api_key_configured"]:
            print("‚úÖ Gemini AI configured and ready")
            logger.info("‚úÖ Gemini AI configured and ready")
        else:
            print("‚ö†Ô∏è Gemini API key not configured - using rule-based fallback")
            logger.warning("‚ö†Ô∏è Gemini API key not configured - using rule-based fallback")
    else:
        print("‚ö†Ô∏è Gemini AI Service not available - using enhanced rule-based analysis")
        logger.warning("‚ö†Ô∏è Gemini AI Service not available")

@app.get("/")
async def read_root():
    """API Health check"""
    gemini_status = "not_available"
    if GEMINI_SERVICE_CLASS:
        config = setup_gemini_config()
        if config["api_key_configured"]:
            gemini_status = "ready"
        else:
            gemini_status = "no_api_key"
    
    return {
        "message": "Post-Test Survey Analysis Dashboard API",
        "status": "running",
        "nlp_ready": nlp_processor is not None and (nlp_processor.is_ready() if hasattr(nlp_processor, 'is_ready') else True),
        "nlp_processor_class": NLP_PROCESSOR_CLASS.__name__ if NLP_PROCESSOR_CLASS else "None",
        "gemini_ai_status": gemini_status,
        "gemini_service_class": GEMINI_SERVICE_CLASS.__name__ if GEMINI_SERVICE_CLASS else "None",
        "version": "3.0.0",
        "features": [
            "Enhanced Thai language processing",
            "Survey-specific sentiment analysis", 
            "Advanced keyword extraction",
            "Post-Test Survey optimization",
            "Gemini AI Integration",
            "Enhanced AI Insights",
            "SSense API Integration",
            "Multiple Analysis Methods"
        ],
        "available_methods": {
            0: "Rule-based Analysis",
            1: "GzipModel (Trained)",
            2: "SSense API (AI for Thai)"
        },
        "timestamp": datetime.now().isoformat()
    }

@app.post("/api/analyze-survey")
async def analyze_survey(file: UploadFile = File(...)):
    """
    Analyze uploaded Post-Test Survey Excel/CSV file with Enhanced AI Insights
    """
    try:
        logger.info(f"üìä Processing Post-Test Survey file: {file.filename}")
        
        # Validate file
        if not file.filename:
            raise HTTPException(status_code=400, detail="No file provided")
        
        if not file.filename.endswith(('.xlsx', '.xls', '.csv')):
            raise HTTPException(
                status_code=400, 
                detail="Unsupported file format. Please use Excel (.xlsx, .xls) or CSV (.csv)"
            )
        
        # Read file contents
        contents = await file.read()
        
        # Parse file based on extension
        try:
            if file.filename.endswith(('.xlsx', '.xls')):
                df = pd.read_excel(io.BytesIO(contents))
            else:
                df = pd.read_csv(io.BytesIO(contents))
        except Exception as e:
            raise HTTPException(
                status_code=400, 
                detail=f"Error reading file: {str(e)}"
            )
        
        logger.info(f"üìä Data loaded: {df.shape[0]} rows, {df.shape[1]} columns")
        
        # Check if NLP processor is available
        if not nlp_processor or not hasattr(nlp_processor, 'analyze_survey'):
            raise HTTPException(
                status_code=503,
                detail="NLP processor is not available. Please check server configuration."
            )
        
        try:
            print("üéØ Using enhanced NLP processor for analysis")
            analysis_id = f"posttest_survey_{file.filename}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            start_time = datetime.now()
            
            # Run NLP analysis
            nlp_results = await nlp_processor.analyze_survey(df, analysis_id)
            
            processing_time = (datetime.now() - start_time).total_seconds()
            logger.info(f"‚úÖ NLP analysis completed in {processing_time:.2f}s")
            
            # Enhance insights with Gemini AI
            ai_start_time = datetime.now()
            try:
                print("ü§ñ Enhancing insights with Gemini AI...")
                
                if GEMINI_SERVICE_CLASS and gemini_ai_key:
                    enhanced_insights = await enhance_insights_with_ai(nlp_results, gemini_ai_key)
                    ai_processing_time = (datetime.now() - ai_start_time).total_seconds()
                    
                    if enhanced_insights.get("ai_generated", False):
                        print(f"‚úÖ Gemini AI insights generated in {ai_processing_time:.2f}s")
                        logger.info(f"‚úÖ Gemini AI insights generated in {ai_processing_time:.2f}s")
                        nlp_results["insights"] = enhanced_insights
                        ai_method = "Gemini AI + Enhanced Rules"
                    else:
                        print("‚ö†Ô∏è Using enhanced rule-based insights (Gemini fallback)")
                        nlp_results["insights"] = enhanced_insights
                        ai_method = "Enhanced Rule-based (Gemini Fallback)"
                else:
                    print("‚ö†Ô∏è Gemini AI not available, using enhanced rule-based analysis")
                    # nlp_results already has insights from NLP processor
                    ai_method = "Enhanced Rule-based Analysis"
                    ai_processing_time = 0
                    
            except Exception as e:
                logger.error(f"‚ùå AI enhancement failed: {e}")
                print(f"‚ùå AI enhancement failed, using rule-based: {e}")
                # Keep existing insights from NLP processor
                ai_method = "Enhanced Rule-based (AI Error Fallback)"
                ai_processing_time = 0
            
        except Exception as e:
            print(f"‚ùå NLP analysis failed: {e}")
            logger.error(f"‚ùå NLP analysis failed: {e}")
            import traceback
            traceback.print_exc()
            raise HTTPException(
                status_code=500,
                detail=f"Analysis failed: {str(e)}"
            )
        
        # Calculate processing summary (‡πÄ‡∏≠‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏≠‡∏≠‡∏Å)
        processing_summary = {
            "status": "completed",
            "processing_time": f"{processing_time:.2f} seconds",
            "ai_processing_time": f"{ai_processing_time:.2f} seconds" if 'ai_processing_time' in locals() else "0.00 seconds",
            "keywords_extracted": len(nlp_results.get("top_keywords", [])),
            "analysis_method": ai_method if 'ai_method' in locals() else nlp_results.get("model_info", {}).get("engine", "Enhanced NLP Analysis"),
            "ai_enhancement": GEMINI_SERVICE_CLASS is not None and gemini_ai_key is not None,
            "method_used": nlp_results.get("model_info", {}).get("method_name", "Unknown")
        }
        
        # Combine all results
        final_results = {
            **nlp_results,
            "file_info": {
                "filename": file.filename,
                "total_responses": len(df),
                "upload_time": datetime.now().isoformat(),
                "columns": len(df.columns),
                "survey_type": "Post-Test Survey",
                "analysis_version": "3.0.0",
                "ai_enhanced": processing_summary["ai_enhancement"]
            },
            "processing_summary": processing_summary
        }
        
        logger.info(f"‚úÖ Analysis completed successfully")
        logger.info(f"üìä Results: {final_results.get('texts_analyzed', 0)} texts, {len(final_results.get('top_keywords', []))} keywords")
        logger.info(f"ü§ñ AI Enhancement: {processing_summary['ai_enhancement']}")
        logger.info(f"üîß Method Used: {processing_summary['method_used']}")
        
        return JSONResponse(content=final_results)
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Unexpected error processing survey: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Analysis failed: {str(e)}")

@app.post("/api/set-analysis-method")
async def set_analysis_method(method_data: dict):
    """‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå"""
    try:
        method_id = method_data.get("method", 0)
        
        if not nlp_processor:
            raise HTTPException(status_code=503, detail="NLP processor not available")
        
        success = nlp_processor.set_analysis_method(method_id)
        
        if success:
            # Re-initialize if needed
            if method_id == 2:  # SSense API
                await nlp_processor._test_ssense_api()
            elif method_id == 1:  # GzipModel
                if hasattr(nlp_processor, '_load_and_train_gzip_model'):
                    await nlp_processor._load_and_train_gzip_model()
            
            model_info = nlp_processor.get_model_info()
            return {
                "success": True,
                "current_method": method_id,
                "method_name": model_info["method_name"],
                "model_info": model_info
            }
        else:
            raise HTTPException(status_code=400, detail=f"Invalid method {method_id}")
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error setting analysis method: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to set method: {str(e)}")

@app.get("/api/analysis-methods")
async def get_analysis_methods():
    """‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ"""
    try:
        if not nlp_processor:
            return {
                "current_method": None,
                "available_methods": {
                    0: {"name": "Rule-based", "description": "‡∏Å‡∏é‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÑ‡∏ß‡πâ"},
                    1: {"name": "GzipModel", "description": "‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πâ‡∏ß‡∏¢ PyThaiNLP", "requires": "PyThaiNLP"},
                    2: {"name": "SSense API", "description": "AI for Thai API", "requires": "Internet connection"}
                }
            }
        
        model_info = nlp_processor.get_model_info()
        available_methods = nlp_processor.get_available_methods()
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
        enhanced_methods = {}
        for method_id, method_info in available_methods.items():
            enhanced_info = method_info.copy()
            
            if method_id == 0:
                enhanced_info["description"] = "‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏é‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÑ‡∏ß‡πâ"
                enhanced_info["pros"] = ["‡πÄ‡∏£‡πá‡∏ß", "‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ô‡πá‡∏ï", "‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£"]
                enhanced_info["cons"] = ["‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á"]
            elif method_id == 1:
                enhanced_info["description"] = "‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πâ‡∏ß‡∏¢ PyThaiNLP GzipModel"
                enhanced_info["pros"] = ["‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á", "‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"]
                enhanced_info["cons"] = ["‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ó‡∏£‡∏ô", "‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ PyThaiNLP"]
                enhanced_info["requires"] = "PyThaiNLP"
                enhanced_info["trained"] = model_info.get("method_specific", {}).get("gzip_trained", False)
            elif method_id == 2:
                enhanced_info["description"] = "AI for Thai SSense API"
                enhanced_info["pros"] = ["‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î", "‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏•‡∏∂‡∏Å", "‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î"]
                enhanced_info["cons"] = ["‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ô‡πá‡∏ï", "‡∏≠‡∏≤‡∏à‡∏ä‡πâ‡∏≤‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢"]
                enhanced_info["requires"] = "Internet connection"
                enhanced_info["api_available"] = model_info.get("method_specific", {}).get("ssense_api_key", False)
            
            enhanced_methods[method_id] = enhanced_info
        
        return {
            "current_method": model_info["analysis_method"],
            "current_method_name": model_info["method_name"],
            "available_methods": enhanced_methods,
            "features": model_info.get("features", {}),
            "pythainlp_available": model_info.get("pythainlp_available", False)
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error getting analysis methods: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to get methods: {str(e)}")

@app.get("/api/gemini-config")
async def get_gemini_config():
    """Get Gemini AI configuration status"""
    try:
        if GEMINI_SERVICE_CLASS:
            config = setup_gemini_config()
            return {
                "gemini_available": True,
                "status": config,
                "service_class": GEMINI_SERVICE_CLASS.__name__,
                "api_key_env_var": "GEMINI_API_KEY"
            }
        else:
            return {
                "gemini_available": False,
                "status": {
                    "api_key_configured": False,
                    "fallback_available": True,
                    "instructions": [
                        "Gemini AI Service not imported",
                        "Using enhanced rule-based analysis only"
                    ]
                },
                "service_class": None
            }
    except Exception as e:
        logger.error(f"‚ùå Error getting Gemini config: {e}")
        return {
            "gemini_available": False,
            "error": str(e),
            "status": {"fallback_available": True}
        }

@app.post("/api/test-gemini")
async def test_gemini_integration():
    """Test Gemini AI integration with sample data"""
    try:
        if not GEMINI_SERVICE_CLASS:
            raise HTTPException(
                status_code=503,
                detail="Gemini AI Service not available"
            )
        
        if not gemini_ai_key:
            raise HTTPException(
                status_code=400,
                detail="Gemini API key not configured. Set GEMINI_API_KEY environment variable."
            )
        
        # Sample data for testing
        test_data = {
            "sentiment_summary": {"positive": 15, "neutral": 8, "negative": 7},
            "top_keywords": ["‡∏™‡∏∞‡∏î‡∏ß‡∏Å", "‡∏á‡πà‡∏≤‡∏¢", "‡∏ä‡πâ‡∏≤", "‡∏™‡∏±‡∏ö‡∏™‡∏ô", "‡∏î‡∏µ"],
            "negative_feedback_samples": [
                "‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏™‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢",
                "‡∏õ‡∏∏‡πà‡∏° edit ‡∏´‡∏≤‡∏¢‡∏≤‡∏Å",
                "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏™‡∏±‡∏ö‡∏™‡∏ô"
            ],
            "positive_feedback_samples": [
                "‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢ ‡∏™‡∏∞‡∏î‡∏ß‡∏Å‡∏î‡∏µ",
                "‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏≤‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£",
                "‡πÄ‡∏£‡πá‡∏ß‡∏î‡∏µ"
            ],
            "likert_scores": {
                "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏á‡πà‡∏≤‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô": 3.8,
                "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏á‡πà‡∏≤‡∏¢‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°": 3.5
            },
            "choice_results": {
                "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡πÉ‡∏à‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á": {"‡∏™‡∏ô‡πÉ‡∏à": 20, "‡πÑ‡∏°‡πà‡∏™‡∏ô‡πÉ‡∏à": 10}
            }
        }
        
        ai_service = GEMINI_SERVICE_CLASS(api_key=gemini_ai_key)
        result = await ai_service.generate_survey_insights(test_data)
        
        return {
            "test_status": "success",
            "ai_insights": result,
            "timestamp": datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Gemini test failed: {e}")
        return {
            "test_status": "failed",
            "error": str(e),
            "fallback_used": True,
            "timestamp": datetime.now().isoformat()
        }

@app.post("/api/test-ssense")
async def test_ssense_integration():
    """Test SSense API integration"""
    try:
        if not nlp_processor:
            raise HTTPException(status_code=503, detail="NLP processor not available")
        
        # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ SSense API
        test_texts = [
            "‡∏£‡∏∞‡∏ö‡∏ö‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢‡∏°‡∏≤‡∏Å ‡∏ä‡∏≠‡∏ö‡πÄ‡∏•‡∏¢",
            "‡∏ä‡πâ‡∏≤‡∏°‡∏≤‡∏Å ‡∏™‡∏±‡∏ö‡∏™‡∏ô‡∏°‡∏≤‡∏Å",
            "‡∏õ‡∏∏‡πà‡∏°‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏´‡∏≤‡∏¢‡∏≤‡∏Å ‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á"
        ]
        
        results = []
        
        # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô SSense method ‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
        original_method = nlp_processor.analysis_method
        nlp_processor.set_analysis_method(2)  # SSense API
        
        try:
            for text in test_texts:
                # ‡πÉ‡∏ä‡πâ async version
                result = await nlp_processor.predict_sentiment_async(text)
                results.append(result)
        finally:
            # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏Å‡∏•‡∏±‡∏ö
            nlp_processor.set_analysis_method(original_method)
        
        return {
            "test_status": "success",
            "ssense_results": results,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"‚ùå SSense test failed: {e}")
        return {
            "test_status": "failed",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@app.get("/api/export/{format}")
async def export_data(format: str):
    """Export analysis results in different formats"""
    try:
        if format not in ["csv", "excel", "json"]:
            raise HTTPException(status_code=400, detail="Unsupported export format. Use: csv, excel, json")
        
        # This endpoint would need to store/retrieve previous analysis results
        # For now, return an error indicating no data
        raise HTTPException(
            status_code=404, 
            detail="No analysis data available for export. Please analyze a survey first."
        )
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Export error: {e}")
        raise HTTPException(status_code=500, detail=f"Export failed: {str(e)}")

@app.get("/api/health")
async def health_check():
    """Comprehensive health check endpoint"""
    nlp_status = "ready" if (nlp_processor is not None and nlp_processor.is_ready()) else "unavailable"
    
    # Check Gemini status
    gemini_status = "not_available"
    if GEMINI_SERVICE_CLASS:
        config = setup_gemini_config()
        if config["api_key_configured"]:
            gemini_status = "ready"
        else:
            gemini_status = "no_api_key"
    
    # Get current analysis method info
    current_method_info = {}
    if nlp_processor:
        model_info = nlp_processor.get_model_info()
        current_method_info = {
            "current_method": model_info.get("analysis_method", 0),
            "method_name": model_info.get("method_name", "Unknown"),
            "available_methods": model_info.get("available_methods", {})
        }
    
    return {
        "status": "healthy",
        "service": "Post-Test Survey Analysis API",
        "version": "3.0.0",
        "nlp_status": nlp_status,
        "nlp_engine": nlp_processor.__class__.__name__ if nlp_processor else "None",
        "nlp_processor_class": NLP_PROCESSOR_CLASS.__name__ if NLP_PROCESSOR_CLASS else "None",
        "gemini_ai_status": gemini_status,
        "gemini_service_class": GEMINI_SERVICE_CLASS.__name__ if GEMINI_SERVICE_CLASS else "None",
        "api_key_configured": bool(gemini_ai_key),
        "analysis_methods": current_method_info,
        "features": {
            "thai_language_processing": True,
            "survey_specific_analysis": True,
            "advanced_sentiment_analysis": True,
            "keyword_extraction": True,
            "likert_scale_analysis": True,
            "choice_question_analysis": True,
            "gemini_ai_integration": GEMINI_SERVICE_CLASS is not None,
            "enhanced_ai_insights": GEMINI_SERVICE_CLASS is not None and bool(gemini_ai_key),
            "export_functionality": True,
            "ssense_api_integration": True,
            "multiple_analysis_methods": True
        },
        "supported_formats": ["xlsx", "xls", "csv"],
        "ai_capabilities": {
            "rule_based_analysis": True,
            "gzip_model_analysis": True,
            "ssense_api_analysis": True,
            "gemini_ai_enhancement": GEMINI_SERVICE_CLASS is not None and bool(gemini_ai_key),
            "fallback_available": True
        },
        "timestamp": datetime.now().isoformat()
    }

if __name__ == "__main__":
    import uvicorn
    
    # Print startup information
    print("\n" + "="*60)
    print("üöÄ POST-TEST SURVEY ANALYSIS API v3.0.0")
    print("="*60)
    print(f"üìä NLP Processor: {'‚úÖ Ready' if NLP_PROCESSOR_CLASS else '‚ùå Not Available'}")
    print(f"ü§ñ Gemini AI: {'‚úÖ Available' if GEMINI_SERVICE_CLASS else '‚ùå Not Available'}")
    print(f"üîë API Key: {'‚úÖ Configured' if gemini_ai_key else '‚ö†Ô∏è Not Set'}")
    print(f"üåê SSense API: ‚úÖ Available")
    print("="*60)
    print("üìã Analysis Methods Available:")
    print("   0: Rule-based Analysis (Fast, Reliable)")
    print("   1: GzipModel Analysis (Trained, Accurate)")
    print("   2: SSense API Analysis (AI for Thai, Most Accurate)")
    print("="*60)
    print("üåê Starting server on http://0.0.0.0:8000")
    print("üìñ API Documentation: http://0.0.0.0:8000/docs")
    print("‚ù§Ô∏è Health Check: http://0.0.0.0:8000/api/health")
    print("üîß Analysis Methods: http://0.0.0.0:8000/api/analysis-methods")
    print("="*60 + "\n")
    
    uvicorn.run(app, host="0.0.0.0", port=8000, reload=True)