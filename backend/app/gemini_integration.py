import os
import json
import asyncio
import aiohttp
from typing import Dict, List, Any, Optional
import logging
from datetime import datetime

# Setup logging
logger = logging.getLogger(__name__)

class GeminiAIService:
    """
    Enhanced Gemini AI Service ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Survey Analysis
    ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API ‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ï‡∏¥‡∏° JSON ‡∏ó‡∏µ‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô
    """
    
    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or os.getenv('GEMINI_API_KEY')
        self.base_url = "https://generativelanguage.googleapis.com/v1beta/models"
        self.timeout = 30  # ‡∏•‡∏î‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÅ‡∏ï‡πà‡∏•‡∏∞ call ‡∏à‡∏∞‡πÄ‡∏•‡πá‡∏Å‡∏•‡∏á
        self.max_retries = 2
        
        # Model priority list (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏Ñ‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£)
        self.models = [
            {
                "name": "gemini-2.0-flash",
                "description": "Next generation features",
                "timeout": 25,
                "max_tokens": 1200,
                "temperature": 0.2
            }
        ]
        
        logger.info(f"ü§ñ Gemini AI Service initialized with incremental analysis")
    
    async def generate_survey_insights(self, survey_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á AI Insights ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô (Multi-step approach)
        """
        try:
            if not self.api_key:
                logger.warning("‚ö†Ô∏è No Gemini API key provided")
                return self._create_fallback_insights(survey_data)
            
            logger.info("üöÄ Starting incremental Gemini AI analysis...")
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á base insights structure
            insights = {
                "executive_summary": "",
                "positive_aspects": [],
                "negative_aspects": [],
                "recommendations": [],
                "system_strengths": [],
                "improvement_areas": [],
                "user_pain_points": [],
                "priority_actions": [],
                "sentiment_analysis": {
                    "overall_mood": "",
                    "satisfaction_level": "",
                    "confidence_score": 0.0
                }
            }
            
            # Step 1: ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏° + sentiment analysis
            logger.info("üìä Step 1: Analyzing overall sentiment...")
            sentiment_data = await self._analyze_sentiment_summary(survey_data)
            insights.update(sentiment_data)
            
            # Step 2: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏∏‡∏î‡πÅ‡∏Ç‡πá‡∏á (positive aspects + system strengths)
            logger.info("‚úÖ Step 2: Analyzing positive aspects...")
            positive_data = await self._analyze_positive_aspects(survey_data)
            insights.update(positive_data)
            
            # Step 3: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏õ‡∏±‡∏ç‡∏´‡∏≤ (negative aspects + pain points)
            logger.info("‚ùå Step 3: Analyzing problems and pain points...")
            negative_data = await self._analyze_negative_aspects(survey_data)
            insights.update(negative_data)
            
            # Step 4: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞ (recommendations + priority actions)
            logger.info("üí° Step 4: Generating recommendations...")
            recommendations_data = await self._generate_recommendations(survey_data, insights)
            insights.update(recommendations_data)
            
            # Step 5: ‡∏™‡∏£‡∏∏‡∏õ executive summary
            logger.info("üìã Step 5: Creating executive summary...")
            summary_data = await self._create_executive_summary(survey_data, insights)
            insights.update(summary_data)
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏° metadata
            insights.update({
                "ai_generated": True,
                "analysis_timestamp": datetime.now().isoformat(),
                "data_points_analyzed": self._count_data_points(survey_data),
                "analysis_method": "Gemini AI Multi-Step Analysis",
                "steps_completed": 5
            })
            
            logger.info("‚úÖ Incremental Gemini AI analysis completed successfully")
            return insights
            
        except Exception as e:
            logger.error(f"‚ùå Gemini AI analysis failed: {e}")
            return self._create_fallback_insights(survey_data)
    
    async def _analyze_sentiment_summary(self, survey_data: Dict[str, Any]) -> Dict[str, Any]:
        """Step 1: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå sentiment ‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°"""
        sentiment_summary = survey_data.get("sentiment_summary", {})
        total_feedback = sum(sentiment_summary.values())
        
        if total_feedback == 0:
            return {
                "sentiment_analysis": {
                    "overall_mood": "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÑ‡∏î‡πâ",
                    "satisfaction_level": "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•",
                    "confidence_score": 0.0
                }
            }
        
        positive_rate = (sentiment_summary.get("positive", 0) / total_feedback) * 100
        
        prompt = f"""‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå sentiment ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Survey ‡∏ô‡∏µ‡πâ:

üìä ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Sentiment:
- Positive: {sentiment_summary.get('positive', 0)} responses ({positive_rate:.1f}%)
- Neutral: {sentiment_summary.get('neutral', 0)} responses
- Negative: {sentiment_summary.get('negative', 0)} responses
- ‡∏£‡∏ß‡∏°: {total_feedback} responses

üí≠ Top Keywords: {', '.join(survey_data.get('top_keywords', [])[:8])}

üîç ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Negative feedback:
{self._format_sample_texts(survey_data.get('negative_feedback_samples', [])[:3])}

üòä ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Positive feedback:
{self._format_sample_texts(survey_data.get('positive_feedback_samples', [])[:3])}

‡πÉ‡∏´‡πâ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON format ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô:
{{
  "sentiment_analysis": {{
    "overall_mood": "‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ (1-2 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ)",
    "satisfaction_level": "‡∏™‡∏π‡∏á/‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á/‡∏ï‡πà‡∏≥ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏™‡∏±‡πâ‡∏ô‡πÜ",
    "confidence_score": 0.XX (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå 0-1)
  }}
}}"""

        try:
            response = await self._call_gemini_api(prompt)
            return self._parse_json_response(response, {
                "sentiment_analysis": {
                    "overall_mood": "‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏•‡∏≤‡∏á",
                    "satisfaction_level": "‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á",
                    "confidence_score": 0.7
                }
            })
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Sentiment analysis failed: {e}")
            return {
                "sentiment_analysis": {
                    "overall_mood": "‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏•‡∏≤‡∏á" if positive_rate < 60 else "‡πÄ‡∏ä‡∏¥‡∏á‡∏ö‡∏ß‡∏Å",
                    "satisfaction_level": "‡∏™‡∏π‡∏á" if positive_rate >= 70 else "‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á" if positive_rate >= 50 else "‡∏ï‡πà‡∏≥",
                    "confidence_score": 0.75
                }
            }
    
    async def _analyze_positive_aspects(self, survey_data: Dict[str, Any]) -> Dict[str, Any]:
        """Step 2: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏∏‡∏î‡πÅ‡∏Ç‡πá‡∏á‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏î‡∏µ"""
        
        positive_samples = survey_data.get('positive_feedback_samples', [])[:5]
        likert_scores = survey_data.get('likert_scores', {})
        
        # ‡∏´‡∏≤ likert scores ‡∏ó‡∏µ‡πà‡∏™‡∏π‡∏á
        high_scores = {k: v for k, v in likert_scores.items() if v >= 4.0}
        
        prompt = f"""‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏∏‡∏î‡πÅ‡∏Ç‡πá‡∏á‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏î‡∏µ‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ:

üòä ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Positive Feedback:
{self._format_sample_texts(positive_samples)}

üìä ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ó‡∏µ‡πà‡∏î‡∏µ (‚â•4.0):
{self._format_scores(high_scores)}

üîë Keywords ‡πÄ‡∏ä‡∏¥‡∏á‡∏ö‡∏ß‡∏Å: {', '.join([kw for kw in survey_data.get('top_keywords', []) if kw in ['‡∏™‡∏∞‡∏î‡∏ß‡∏Å', '‡∏á‡πà‡∏≤‡∏¢', '‡πÄ‡∏£‡πá‡∏ß', '‡∏î‡∏µ', '‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°', '‡∏ä‡∏≠‡∏ö', '‡πÑ‡∏°‡πà‡∏¢‡∏≤‡∏Å']])}

‡πÉ‡∏´‡πâ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON format ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô:
{{
  "positive_aspects": [
    "‡∏à‡∏∏‡∏î‡πÅ‡∏Ç‡πá‡∏á‡∏ó‡∏µ‡πà 1 ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô",
    "‡∏à‡∏∏‡∏î‡πÅ‡∏Ç‡πá‡∏á‡∏ó‡∏µ‡πà 2 ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô", 
    "‡∏à‡∏∏‡∏î‡πÅ‡∏Ç‡πá‡∏á‡∏ó‡∏µ‡πà 3 ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô"
  ],
  "system_strengths": [
    "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡πÇ‡∏î‡∏î‡πÄ‡∏î‡πà‡∏ô",
    "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡πÇ‡∏î‡∏î‡πÄ‡∏î‡πà‡∏ô"
  ]
}}"""

        try:
            response = await self._call_gemini_api(prompt)
            return self._parse_json_response(response, {
                "positive_aspects": ["‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô"],
                "system_strengths": ["‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡πÑ‡∏ß‡πâ"]
            })
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Positive analysis failed: {e}")
            return self._generate_positive_fallback(survey_data)
    
    async def _analyze_negative_aspects(self, survey_data: Dict[str, Any]) -> Dict[str, Any]:
        """Step 3: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏à‡∏∏‡∏î‡∏≠‡πà‡∏≠‡∏ô"""
        
        negative_samples = survey_data.get('negative_feedback_samples', [])[:5]
        likert_scores = survey_data.get('likert_scores', {})
        
        # ‡∏´‡∏≤ likert scores ‡∏ó‡∏µ‡πà‡∏ï‡πà‡∏≥
        low_scores = {k: v for k, v in likert_scores.items() if v < 3.5}
        
        prompt = f"""‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ:

‚ùå ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Negative Feedback:
{self._format_sample_texts(negative_samples)}

üìâ ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πà‡∏≥ (<3.5):
{self._format_scores(low_scores)}

‚ö†Ô∏è Keywords ‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏ö: {', '.join([kw for kw in survey_data.get('top_keywords', []) if kw in ['‡∏ä‡πâ‡∏≤', '‡∏¢‡∏≤‡∏Å', '‡∏™‡∏±‡∏ö‡∏™‡∏ô', '‡∏õ‡∏±‡∏ç‡∏´‡∏≤', '‡πÑ‡∏°‡πà‡∏î‡∏µ', '‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç', '‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á', '‡∏´‡∏≤‡∏¢‡∏≤‡∏Å']])}

‡πÉ‡∏´‡πâ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON format ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô:
{{
  "negative_aspects": [
    "‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà 1 ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏",
    "‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà 2 ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏",
    "‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà 3 ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏"
  ],
  "improvement_areas": [
    "‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÄ‡∏£‡πà‡∏á‡∏î‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1",
    "‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÄ‡∏£‡πà‡∏á‡∏î‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 2"
  ],
  "user_pain_points": [
    "‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡∏ó‡∏µ‡πà 1",
    "‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡∏ó‡∏µ‡πà 2"
  ]
}}"""

        try:
            response = await self._call_gemini_api(prompt)
            return self._parse_json_response(response, {
                "negative_aspects": [],
                "improvement_areas": [],
                "user_pain_points": []
            })
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Negative analysis failed: {e}")
            return self._generate_negative_fallback(survey_data)
    
    async def _generate_recommendations(self, survey_data: Dict[str, Any], current_insights: Dict[str, Any]) -> Dict[str, Any]:
        """Step 4: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡πÅ‡∏•‡∏∞‡πÅ‡∏ú‡∏ô‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥"""
        
        # ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö
        problems = current_insights.get('negative_aspects', []) + current_insights.get('user_pain_points', [])
        strengths = current_insights.get('positive_aspects', []) + current_insights.get('system_strengths', [])
        
        prompt = f"""‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Survey ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡πÅ‡∏•‡∏∞‡πÅ‡∏ú‡∏ô‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥:

üí™ ‡∏à‡∏∏‡∏î‡πÅ‡∏Ç‡πá‡∏á‡∏ó‡∏µ‡πà‡∏û‡∏ö:
{self._format_list_items(strengths[:4])}

‚ö†Ô∏è ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö:
{self._format_list_items(problems[:4])}

üìä Sentiment: {current_insights.get('sentiment_analysis', {}).get('satisfaction_level', '‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á')}

üéØ ‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡∏ó‡∏µ‡πà:
- ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡∏ò‡∏£‡∏£‡∏°‡πÅ‡∏•‡∏∞‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á
- ‡∏°‡∏µ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô  
- ‡∏Ñ‡∏≥‡∏ô‡∏∂‡∏á‡∏ñ‡∏∂‡∏á‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡πÅ‡∏•‡∏∞‡πÄ‡∏ß‡∏•‡∏≤

‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON format ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô:
{{
  "recommendations": [
    "‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡∏ó‡∏µ‡πà 1 ‡∏û‡∏£‡πâ‡∏≠‡∏° ROI/‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á",
    "‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡∏ó‡∏µ‡πà 2 ‡∏û‡∏£‡πâ‡∏≠‡∏° timeline ‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô",
    "‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡∏ó‡∏µ‡πà 3 ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£",
    "‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡∏ó‡∏µ‡πà 4 ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥"
  ],
  "priority_actions": [
    "‡∏á‡∏≤‡∏ô‡πÄ‡∏£‡πà‡∏á‡∏î‡πà‡∏ß‡∏ô (0-30 ‡∏ß‡∏±‡∏ô) ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á",
    "‡∏á‡∏≤‡∏ô‡∏£‡∏∞‡∏¢‡∏∞‡∏™‡∏±‡πâ‡∏ô (1-3 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô) ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£",
    "‡∏á‡∏≤‡∏ô‡∏£‡∏∞‡∏¢‡∏∞‡∏¢‡∏≤‡∏ß (3-12 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô) ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡πÄ‡∏ä‡∏¥‡∏á‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå"
  ]
}}"""

        try:
            response = await self._call_gemini_api(prompt)
            return self._parse_json_response(response, {
                "recommendations": [
                    "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå feedback ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤‡∏à‡∏∏‡∏î‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á",
                    "‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ",
                    "‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á"
                ],
                "priority_actions": [
                    "‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° (1-4 ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå)",
                    "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏ó‡∏≥‡πÅ‡∏ú‡∏ô‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á (1-2 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)",
                    "‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏ï‡∏≤‡∏°‡πÅ‡∏ú‡∏ô (3-6 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)"
                ]
            })
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Recommendations generation failed: {e}")
            return self._generate_recommendations_fallback(survey_data)
    
    async def _create_executive_summary(self, survey_data: Dict[str, Any], insights: Dict[str, Any]) -> Dict[str, Any]:
        """Step 5: ‡∏™‡∏£‡πâ‡∏≤‡∏á executive summary"""
        
        sentiment_summary = survey_data.get("sentiment_summary", {})
        total_feedback = sum(sentiment_summary.values())
        positive_rate = (sentiment_summary.get("positive", 0) / total_feedback * 100) if total_feedback > 0 else 0
        
        key_findings = []
        key_findings.extend(insights.get('positive_aspects', [])[:2])
        key_findings.extend(insights.get('negative_aspects', [])[:2])
        
        prompt = f"""‡∏™‡∏£‡πâ‡∏≤‡∏á Executive Summary ‡∏à‡∏≤‡∏Å‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå:

üìä ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô:
- ‡∏ú‡∏π‡πâ‡∏ï‡∏≠‡∏ö 31 ‡∏Ñ‡∏ô: {total_feedback} ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö
- ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏∂‡∏á‡∏û‡∏≠‡πÉ‡∏à: {positive_rate:.1f}%
- ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏∂‡∏á‡∏û‡∏≠‡πÉ‡∏à: {insights.get('sentiment_analysis', {}).get('satisfaction_level', '‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á')}

üîç ‡∏Ç‡πâ‡∏≠‡∏Ñ‡πâ‡∏ô‡∏û‡∏ö‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:
{self._format_list_items(key_findings[:4])}

üí° ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡∏´‡∏•‡∏±‡∏Å:
{self._format_list_items(insights.get('recommendations', [])[:2])}

‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á Executive Summary ‡∏ó‡∏µ‡πà:
- ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö 2-3 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ
- ‡πÄ‡∏ô‡πâ‡∏ô‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πà‡∏≠‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à
- ‡∏£‡∏∞‡∏ö‡∏∏‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏´‡∏•‡∏±‡∏Å

‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON format ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô:
{{
  "executive_summary": "‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå 2-3 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ ‡πÄ‡∏ô‡πâ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡πâ‡∏ô‡∏û‡∏ö‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πà‡∏≠‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à"
}}"""

        try:
            response = await self._call_gemini_api(prompt)
            result = self._parse_json_response(response, {
                "executive_summary": f"‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå {total_feedback} ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô ‡∏û‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏∂‡∏á‡∏û‡∏≠‡πÉ‡∏à {positive_rate:.1f}% ‡∏£‡∏∞‡∏ö‡∏ö‡∏°‡∏µ‡∏à‡∏∏‡∏î‡πÅ‡∏Ç‡πá‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏ò‡∏≥‡∏£‡∏á‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û"
            })
            return result
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Executive summary generation failed: {e}")
            return {
                "executive_summary": f"‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå {total_feedback} ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô ‡∏û‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏∂‡∏á‡∏û‡∏≠‡πÉ‡∏à {positive_rate:.1f}% ‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á"
            }
    
    # Helper methods
    def _format_sample_texts(self, texts: List[str]) -> str:
        """‡πÅ‡∏õ‡∏•‡∏á list ‡∏Ç‡∏≠‡∏á text ‡πÄ‡∏õ‡πá‡∏ô string ‡∏ó‡∏µ‡πà‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢"""
        if not texts:
            return "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
        
        formatted = []
        for i, text in enumerate(texts[:5], 1):
            clean_text = str(text).replace('"', "'").replace('\n', ' ').strip()[:120]
            if len(str(text)) > 120:
                clean_text += "..."
            formatted.append(f"{i}. {clean_text}")
        
        return "\n".join(formatted)
    
    def _format_scores(self, scores: Dict[str, float]) -> str:
        """‡πÅ‡∏õ‡∏•‡∏á scores ‡πÄ‡∏õ‡πá‡∏ô string"""
        if not scores:
            return "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
        
        items = []
        for aspect, score in scores.items():
            items.append(f"- {aspect}: {score:.2f}/5.0")
        
        return "\n".join(items)
    
    def _format_list_items(self, items: List[str]) -> str:
        """‡πÅ‡∏õ‡∏•‡∏á list ‡πÄ‡∏õ‡πá‡∏ô string ‡πÅ‡∏ö‡∏ö‡∏°‡∏µ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠"""
        if not items:
            return "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
        
        formatted = []
        for i, item in enumerate(items, 1):
            formatted.append(f"{i}. {item}")
        
        return "\n".join(formatted)
    
    def _parse_json_response(self, response: str, fallback: Dict) -> Dict:
        """‡πÅ‡∏õ‡∏•‡∏á response ‡πÄ‡∏õ‡πá‡∏ô JSON ‡∏û‡∏£‡πâ‡∏≠‡∏° fallback"""
        try:
            # ‡∏•‡∏≠‡∏á clean response ‡∏Å‡πà‡∏≠‡∏ô
            cleaned = self._clean_response_text(response)
            
            # ‡∏´‡∏≤ JSON ‡πÉ‡∏ô response
            json_start = cleaned.find('{')
            json_end = cleaned.rfind('}') + 1
            
            if json_start >= 0 and json_end > json_start:
                json_str = cleaned[json_start:json_end]
                parsed = json.loads(json_str)
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ key ‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                if any(key in parsed for key in fallback.keys()):
                    return parsed
            
            return fallback
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è JSON parsing failed: {e}")
            return fallback
    
    def _clean_response_text(self, text: str) -> str:
        """‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î response text"""
        # ‡∏•‡∏ö markdown code blocks
        text = text.replace('```json', '').replace('```', '')
        
        # ‡∏•‡∏ö text ‡∏û‡∏¥‡πÄ‡∏®‡∏©
        lines = text.split('\n')
        cleaned_lines = []
        in_json = False
        
        for line in lines:
            if '{' in line and not in_json:
                in_json = True
                json_start = line.find('{')
                cleaned_lines.append(line[json_start:])
            elif in_json:
                cleaned_lines.append(line)
                if '}' in line and line.count('}') >= line.count('{'):
                    break
        
        return '\n'.join(cleaned_lines)
    
    # Fallback methods
    def _generate_positive_fallback(self, survey_data: Dict) -> Dict:
        """Fallback ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏∏‡∏î‡πÅ‡∏Ç‡πá‡∏á"""
        positive_rate = self._calculate_positive_rate(survey_data)
        
        positive_aspects = []
        system_strengths = []
        
        if positive_rate >= 60:
            positive_aspects.append(f"‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏∂‡∏á‡∏û‡∏≠‡πÉ‡∏à‡∏™‡∏π‡∏á ({positive_rate:.1f}%)")
            system_strengths.append("‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡∏µ")
        
        # ‡πÄ‡∏ä‡πá‡∏Ñ keywords ‡πÄ‡∏ä‡∏¥‡∏á‡∏ö‡∏ß‡∏Å
        positive_keywords = [kw for kw in survey_data.get('top_keywords', []) 
                           if kw in ['‡∏™‡∏∞‡∏î‡∏ß‡∏Å', '‡∏á‡πà‡∏≤‡∏¢', '‡πÄ‡∏£‡πá‡∏ß', '‡∏î‡∏µ', '‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°']]
        if positive_keywords:
            positive_aspects.append(f"‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏ô‡∏ä‡∏°‡πÉ‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á: {', '.join(positive_keywords[:3])}")
        
        # ‡πÄ‡∏ä‡πá‡∏Ñ likert scores
        high_scores = {k: v for k, v in survey_data.get('likert_scores', {}).items() if v >= 4.0}
        if high_scores:
            best_aspect = max(high_scores.items(), key=lambda x: x[1])
            system_strengths.append(f"‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î: {best_aspect[0]} ({best_aspect[1]:.2f}/5)")
        
        return {
            "positive_aspects": positive_aspects or ["‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô"],
            "system_strengths": system_strengths or ["‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡πÑ‡∏ß‡πâ"]
        }
    
    def _generate_negative_fallback(self, survey_data: Dict) -> Dict:
        """Fallback ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤"""
        negative_aspects = []
        improvement_areas = []
        user_pain_points = []
        
        # ‡πÄ‡∏ä‡πá‡∏Ñ keywords ‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏ö
        negative_keywords = [kw for kw in survey_data.get('top_keywords', []) 
                           if kw in ['‡∏ä‡πâ‡∏≤', '‡∏¢‡∏≤‡∏Å', '‡∏™‡∏±‡∏ö‡∏™‡∏ô', '‡∏õ‡∏±‡∏ç‡∏´‡∏≤', '‡πÑ‡∏°‡πà‡∏î‡∏µ']]
        if negative_keywords:
            negative_aspects.append(f"‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏´‡∏•‡∏±‡∏Å: {', '.join(negative_keywords[:3])}")
        
        # ‡πÄ‡∏ä‡πá‡∏Ñ likert scores ‡∏ï‡πà‡∏≥
        low_scores = {k: v for k, v in survey_data.get('likert_scores', {}).items() if v < 3.5}
        if low_scores:
            worst_aspect = min(low_scores.items(), key=lambda x: x[1])
            improvement_areas.append(f"‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÄ‡∏£‡πà‡∏á‡∏î‡πà‡∏ß‡∏ô: {worst_aspect[0]} ({worst_aspect[1]:.2f}/5)")
        
        # ‡πÄ‡∏ä‡πá‡∏Ñ negative samples
        negative_samples = survey_data.get('negative_feedback_samples', [])
        if negative_samples:
            common_issues = []
            for sample in negative_samples[:3]:
                sample_lower = sample.lower()
                if '‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢' in sample_lower:
                    common_issues.append('‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢')
                if '‡∏õ‡∏∏‡πà‡∏°' in sample_lower:
                    common_issues.append('‡∏õ‡∏∏‡πà‡∏°‡πÑ‡∏°‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô')
                if '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà' in sample_lower:
                    common_issues.append('‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏±‡∏ö‡∏™‡∏ô')
            
            user_pain_points.extend(list(set(common_issues)))
        
        return {
            "negative_aspects": negative_aspects,
            "improvement_areas": improvement_areas,
            "user_pain_points": user_pain_points
        }
    
    def _generate_recommendations_fallback(self, survey_data: Dict) -> Dict:
        """Fallback ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞"""
        return {
            "recommendations": [
                "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå feedback ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤‡∏à‡∏∏‡∏î‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô",
                "‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÉ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô",
                "‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á UX/UI ‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏™‡∏∞‡∏î‡∏ß‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô",
                "‡∏à‡∏±‡∏î‡∏ó‡∏≥‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏ö‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô"
            ],
            "priority_actions": [
                "‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà feedback ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° (0-30 ‡∏ß‡∏±‡∏ô)",
                "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏ó‡∏≥‡πÅ‡∏ú‡∏ô‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏£‡∏∞‡∏ö‡∏ö (1-3 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)",
                "‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏ï‡∏≤‡∏°‡πÅ‡∏ú‡∏ô (3-12 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)"
            ]
        }
    
    def _calculate_positive_rate(self, survey_data: Dict) -> float:
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏∂‡∏á‡∏û‡∏≠‡πÉ‡∏à"""
        sentiment_summary = survey_data.get("sentiment_summary", {})
        total = sum(sentiment_summary.values())
        return (sentiment_summary.get("positive", 0) / total * 100) if total > 0 else 0
    
    async def _call_gemini_api(self, prompt: str) -> str:
        """‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Gemini API (‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏°)"""
        if not self.api_key:
            raise ValueError("Gemini API key is required")
        
        last_error = None
        
        for i, model_config in enumerate(self.models):
            model_name = model_config["name"]
            timeout = model_config["timeout"]
            
            try:
                logger.info(f"üîÑ Using model {i+1}/{len(self.models)}: {model_name}")
                
                url = f"{self.base_url}/{model_name}:generateContent?key={self.api_key}"
                
                payload = {
                    "contents": [{
                        "parts": [{"text": prompt}]
                    }],
                    "generationConfig": {
                        "temperature": model_config["temperature"],
                        "topK": 40,
                        "topP": 0.8,
                        "maxOutputTokens": model_config["max_tokens"],
                        "candidateCount": 1
                    },
                    "safetySettings": [
                        {
                            "category": "HARM_CATEGORY_HARASSMENT",
                            "threshold": "BLOCK_MEDIUM_AND_ABOVE"
                        },
                        {
                            "category": "HARM_CATEGORY_HATE_SPEECH",
                            "threshold": "BLOCK_MEDIUM_AND_ABOVE"
                        },
                        {
                            "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", 
                            "threshold": "BLOCK_MEDIUM_AND_ABOVE"
                        },
                        {
                            "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                            "threshold": "BLOCK_MEDIUM_AND_ABOVE"
                        }
                    ]
                }
                
                headers = {
                    "Content-Type": "application/json",
                    "User-Agent": "Survey-Analysis-Dashboard/2.1"
                }
                
                async with aiohttp.ClientSession(
                    timeout=aiohttp.ClientTimeout(total=timeout)
                ) as session:
                    async with session.post(url, json=payload, headers=headers) as response:
                        
                        if response.status == 200:
                            result = await response.json()
                            
                            if (result.get("candidates") and 
                                len(result["candidates"]) > 0 and
                                result["candidates"][0].get("content") and
                                result["candidates"][0]["content"].get("parts") and
                                len(result["candidates"][0]["content"]["parts"]) > 0):
                                
                                content = result["candidates"][0]["content"]["parts"][0]["text"]
                                logger.info(f"‚úÖ Successfully used model: {model_name}")
                                return content
                            else:
                                logger.warning(f"‚ö†Ô∏è Empty response from {model_name}")
                                last_error = ValueError(f"Empty response from {model_name}")
                                continue
                        
                        elif response.status == 404:
                            logger.warning(f"‚ö†Ô∏è Model {model_name} not found (404)")
                            last_error = ValueError(f"Model {model_name} not available")
                            continue
                            
                        elif response.status == 429:
                            logger.warning(f"‚ö†Ô∏è Rate limit exceeded for {model_name}")
                            last_error = ValueError(f"Rate limit for {model_name}")
                            await asyncio.sleep(2)  # ‡∏£‡∏≠‡∏™‡∏±‡πâ‡∏ô‡∏•‡∏á‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÄ‡∏õ‡πá‡∏ô request ‡πÄ‡∏•‡πá‡∏Å
                            continue
                            
                        else:
                            error_text = await response.text()
                            logger.warning(f"‚ö†Ô∏è API error {response.status} for {model_name}")
                            last_error = ValueError(f"API error {response.status}: {error_text}")
                            continue
                
            except asyncio.TimeoutError:
                logger.warning(f"‚è∞ Timeout for {model_name} ({timeout}s)")
                last_error = ValueError(f"Timeout for {model_name}")
                continue
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Error with {model_name}: {str(e)}")
                last_error = e
                continue
        
        # ‡∏´‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å model ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß
        error_msg = f"All {len(self.models)} models failed. Last error: {last_error}"
        logger.error(f"‚ùå {error_msg}")
        raise Exception(error_msg)
    
    def _create_fallback_insights(self, survey_data: Dict[str, Any]) -> Dict[str, Any]:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á fallback insights ‡πÄ‡∏°‡∏∑‡πà‡∏≠ Gemini ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô"""
        sentiment_summary = survey_data.get("sentiment_summary", {})
        total_feedback = sum(sentiment_summary.values())
        
        if total_feedback == 0:
            return {
                "executive_summary": "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå",
                "positive_aspects": [],
                "negative_aspects": [],
                "recommendations": ["‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ"],
                "system_strengths": [],
                "improvement_areas": [],
                "user_pain_points": [],
                "priority_actions": [],
                "sentiment_analysis": {
                    "overall_mood": "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÑ‡∏î‡πâ",
                    "satisfaction_level": "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•",
                    "confidence_score": 0.0
                },
                "ai_generated": False,
                "analysis_method": "Rule-based Fallback (No Data)",
                "steps_completed": 0
            }
        
        positive_rate = (sentiment_summary.get("positive", 0) / total_feedback) * 100
        
        # ‡πÉ‡∏ä‡πâ fallback methods
        positive_data = self._generate_positive_fallback(survey_data)
        negative_data = self._generate_negative_fallback(survey_data)
        recommendations_data = self._generate_recommendations_fallback(survey_data)
        
        insights = {
            "executive_summary": f"‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå {total_feedback} ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô ‡∏û‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏∂‡∏á‡∏û‡∏≠‡πÉ‡∏à {positive_rate:.1f}% ‡∏£‡∏∞‡∏ö‡∏ö‡∏°‡∏µ‡∏à‡∏∏‡∏î‡πÅ‡∏Ç‡πá‡∏á‡πÅ‡∏•‡∏∞‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏£‡∏∞‡∏ö‡∏∏",
            **positive_data,
            **negative_data,
            **recommendations_data,
            "sentiment_analysis": {
                "overall_mood": "‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏•‡∏≤‡∏á" if positive_rate < 60 else "‡πÄ‡∏ä‡∏¥‡∏á‡∏ö‡∏ß‡∏Å",
                "satisfaction_level": "‡∏™‡∏π‡∏á" if positive_rate >= 70 else "‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á" if positive_rate >= 50 else "‡∏ï‡πà‡∏≥",
                "confidence_score": 0.75
            },
            "ai_generated": False,
            "analysis_method": "Enhanced Rule-based Analysis (Fallback)",
            "steps_completed": 5
        }
        
        return insights
    
    def _count_data_points(self, survey_data: Dict[str, Any]) -> int:
        """‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô data points ‡∏ó‡∏µ‡πà‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå"""
        count = 0
        count += len(survey_data.get("top_keywords", []))
        count += len(survey_data.get("negative_feedback_samples", []))
        count += len(survey_data.get("positive_feedback_samples", []))
        count += len(survey_data.get("likert_scores", {}))
        count += sum(survey_data.get("sentiment_summary", {}).values())
        return count
    
    async def list_available_models(self) -> List[Dict[str, str]]:
        """‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ models ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ"""
        if not self.api_key:
            return []
        
        try:
            url = f"{self.base_url}?key={self.api_key}"
            
            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=30)) as session:
                async with session.get(url) as response:
                    if response.status == 200:
                        result = await response.json()
                        models = []
                        for model in result.get("models", []):
                            name = model.get("name", "").replace("models/", "")
                            if "generateContent" in model.get("supportedGenerationMethods", []):
                                models.append({
                                    "name": name,
                                    "display_name": model.get("displayName", name),
                                    "description": model.get("description", ""),
                                    "supported": True
                                })
                        return models
                    else:
                        logger.error(f"Failed to list models: {response.status}")
                        return []
        except Exception as e:
            logger.error(f"Error listing models: {e}")
            return []
    
    def get_service_info(self) -> Dict[str, Any]:
        """‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö service"""
        return {
            "service_name": "Gemini AI Service",
            "version": "2.1.0",
            "api_key_configured": bool(self.api_key),
            "available_models": len(self.models),
            "primary_model": self.models[0]["name"] if self.models else None,
            "analysis_method": "Multi-Step Incremental Analysis",
            "steps": [
                "Sentiment Analysis",
                "Positive Aspects Analysis", 
                "Negative Aspects Analysis",
                "Recommendations Generation",
                "Executive Summary Creation"
            ],
            "features": [
                "Survey Analysis",
                "Incremental Processing",
                "Reduced Timeout Risk",
                "Step-by-step Insights",
                "Thai Language Support",
                "Enhanced Fallback System"
            ]
        }


# Helper functions ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö integration
async def enhance_insights_with_ai(nlp_results: Dict[str, Any], gemini_api_key: str = None) -> Dict[str, Any]:
    """
    ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á insights ‡∏î‡πâ‡∏ß‡∏¢ Gemini AI ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô
    """
    try:
        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Gemini
        survey_data = {
            "sentiment_summary": nlp_results.get("sentiment_distribution", {}),
            "top_keywords": [kw["word"] for kw in nlp_results.get("top_keywords", [])[:10]],
            "negative_feedback_samples": [
                result["text"] for result in nlp_results.get("detailed_results", [])
                if result.get("sentiment") == "negative"
            ][:5],
            "positive_feedback_samples": [
                result["text"] for result in nlp_results.get("detailed_results", [])
                if result.get("sentiment") == "positive"
            ][:5],
            "likert_scores": {
                k: v.get("mean", 0) for k, v in nlp_results.get("likert_analysis", {}).items()
            },
            "choice_results": nlp_results.get("choice_analysis", {})
        }
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á AI service ‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô
        ai_service = GeminiAIService(api_key=gemini_api_key)
        ai_insights = await ai_service.generate_survey_insights(survey_data)
        
        logger.info(f"‚úÖ Successfully enhanced insights with Gemini AI ({ai_insights.get('steps_completed', 0)} steps)")
        return ai_insights
        
    except Exception as e:
        logger.error(f"‚ùå AI enhancement failed: {e}")
        # ‡πÉ‡∏ä‡πâ fallback
        ai_service = GeminiAIService()
        return ai_service._create_fallback_insights({
            "sentiment_summary": nlp_results.get("sentiment_distribution", {}),
            "top_keywords": [kw["word"] for kw in nlp_results.get("top_keywords", [])[:10]]
        })


def setup_gemini_config() -> Dict[str, Any]:
    """
    ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ ‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Gemini configuration
    """
    api_key = os.getenv('GEMINI_API_KEY')
    
    config_info = {
        "api_key_configured": bool(api_key),
        "api_key_length": len(api_key) if api_key else 0,
        "fallback_available": True,
        "service_status": "ready" if api_key else "no_api_key",
        "analysis_method": "Multi-Step Incremental Analysis",
        "advantages": [
            "‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á timeout ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£ generate ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß",
            "‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô", 
            "‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏° cost ‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤",
            "‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• real-time ‡πÑ‡∏î‡πâ",
            "‡∏´‡∏≤‡∏Å‡∏ö‡∏≤‡∏á‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß ‡∏¢‡∏±‡∏á‡πÑ‡∏î‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô"
        ],
        "instructions": [
            "‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ GEMINI_API_KEY ‡πÉ‡∏ô environment variables",
            "‡∏´‡∏£‡∏∑‡∏≠‡∏™‡πà‡∏á API key ‡∏ú‡πà‡∏≤‡∏ô parameter ‡∏Ç‡∏≠‡∏á function",
            "‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á",
            "‡∏´‡∏≤‡∏Å‡∏ö‡∏≤‡∏á‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡πÉ‡∏ä‡πâ enhanced rule-based fallback"
        ]
    }
    
    return config_info


# Test function
async def test_gemini_service(api_key: str = None) -> Dict[str, Any]:
    """
    ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Gemini service ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô
    """
    service = GeminiAIService(api_key=api_key)
    
    test_data = {
        "sentiment_summary": {"positive": 15, "neutral": 8, "negative": 2},
        "top_keywords": ["‡∏™‡∏∞‡∏î‡∏ß‡∏Å", "‡∏á‡πà‡∏≤‡∏¢", "‡πÄ‡∏£‡πá‡∏ß", "‡∏™‡∏±‡∏ö‡∏™‡∏ô"],
        "negative_feedback_samples": ["‡∏õ‡∏∏‡πà‡∏°‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏´‡∏≤‡∏¢‡∏≤‡∏Å", "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏™‡∏±‡∏ö‡∏™‡∏ô"],
        "positive_feedback_samples": ["‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢ ‡∏™‡∏∞‡∏î‡∏ß‡∏Å‡∏î‡∏µ", "‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏≤‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£", "‡πÄ‡∏£‡πá‡∏ß‡∏î‡∏µ"],
        "likert_scores": {"‡∏Ñ‡∏ß‡∏≤‡∏°‡∏á‡πà‡∏≤‡∏¢": 4.2, "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏≠‡πÉ‡∏à": 3.8},
        "choice_results": {"‡∏™‡∏ô‡πÉ‡∏à": {"‡∏™‡∏ô‡πÉ‡∏à": 20, "‡πÑ‡∏°‡πà‡∏™‡∏ô‡πÉ‡∏à": 5}}
    }
    
    try:
        start_time = datetime.now()
        result = await service.generate_survey_insights(test_data)
        processing_time = (datetime.now() - start_time).total_seconds()
        
        return {
            "test_status": "success",
            "processing_time": f"{processing_time:.2f}s",
            "ai_generated": result.get("ai_generated", False),
            "analysis_method": result.get("analysis_method", "unknown"),
            "steps_completed": result.get("steps_completed", 0),
            "insights_count": {
                "positive_aspects": len(result.get("positive_aspects", [])),
                "negative_aspects": len(result.get("negative_aspects", [])),
                "recommendations": len(result.get("recommendations", [])),
                "priority_actions": len(result.get("priority_actions", []))
            },
            "confidence_score": result.get("sentiment_analysis", {}).get("confidence_score", 0),
            "advantages_realized": [
                f"‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÉ‡∏ô {processing_time:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ (‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏°)",
                f"‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à {result.get('steps_completed', 0)}/5 ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô",
                "‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á timeout",
                "‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏° cost ‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤"
            ],
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        return {
            "test_status": "failed",
            "error": str(e),
            "fallback_available": True,
            "timestamp": datetime.now().isoformat()
        }


if __name__ == "__main__":
    import asyncio
    
    # Test configuration
    async def main():
        print("üß™ Testing Enhanced Gemini AI Service (Multi-Step)...")
        
        # Test config
        config = setup_gemini_config()
        print("Configuration:")
        print(json.dumps(config, indent=2, ensure_ascii=False))
        
        # Test service
        if config["api_key_configured"]:
            result = await test_gemini_service()
            print("\nTest Result:")
            print(json.dumps(result, indent=2, ensure_ascii=False))
        else:
            print("\n‚ö†Ô∏è No API key configured. Set GEMINI_API_KEY environment variable.")
    
    asyncio.run(main())